# -*- coding: utf-8 -*-
"""Software Fault classification using NN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xQBz74F_Vqy1GvNQy4LmhRDW6cFLUFmV
"""

from google.colab import drive
drive.mount('/content/gdrive')

import tensorflow as tf
from tensorflow import keras # keras is an API for tensor flow
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# reading the dataset
dataset_csv = pd.read_csv('soft_def.csv')
dataset_csv.head(10)
# print rows and columns
dataset_csv.shape

dataset_csv.dtypes#the ouput shows attribute with type object, which means they are string

dataset_csv.tail()

dataset_csv[pd.to_numeric(dataset_csv.uniq_Op,errors="coerce").isnull()]

df=dataset_csv[dataset_csv.uniq_Op!='?']
df=dataset_csv[dataset_csv.uniq_Opnd!='?']
df=dataset_csv[dataset_csv.total_Op!='?']
df=dataset_csv[dataset_csv.total_Opnd!='?']
df=dataset_csv[dataset_csv.branchCount!='?']

df.dtypes

df.uniq_Op=pd.to_numeric(df.uniq_Op)
df.uniq_Opnd=pd.to_numeric(df.uniq_Opnd)
df.total_Op=pd.to_numeric(df.total_Op)
df.total_Opnd=pd.to_numeric(df.total_Opnd)
df.branchCount=pd.to_numeric(df.branchCount)

df['defects'] = df['defects'].apply(lambda x: 1 if x == 'True' else 0)
print(dataset_csv.head(5))

df.dtypes

for column in df:
  print(column)

for column in df:
      print(f'{column} : {df[column].unique()}')

col_to_scale=['loc',
'v(g)',
'ev(g)',
'iv(g)',
'n',
'v',
'l',
'd',
'i',
'e',
'b',
't',
'lOCode',
'lOComment',
'lOBlank',
'locCodeAndComment',
'uniq_Op',
'uniq_Opnd',
'total_Op',
'total_Opnd',
'branchCount'
]

from sklearn.preprocessing import MinMaxScaler
scaler=MinMaxScaler()

df[col_to_scale]=scaler.fit_transform(df[col_to_scale])

df.sample(4)

x=df.drop('defects',axis='columns')
y=df['defects']

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=5)

model=keras.Sequential([
    keras.layers.Dense(10,activation="relu"), #dense layer is a fully connected layers. 128 is the hiddeen layer nodes
    keras.layers.Dropout(0.2),#DROP 20% OF NEURONS
    keras.layers.Dense(10,activation="relu"),
    keras.layers.Dropout(0.5),##DROP 50% OF NEURONS
    keras.layers.Dense(1,activation="sigmoid")#output layer neurons=10, softmax= pick values for each neuron and so it sums upto one
])

model.compile(optimizer="adam",
              loss="binary_crossentropy",
              metrics=['accuracy']
              )

model.fit(x_train,y_train,epochs=15)

model.evaluate(x_test,y_test)

yp=model.predict(x_test)
yp[:5]#the oupt is a 2D array

#convert 2D to 1D array(if value is less than 0.5-->0 else make it 1)
y_pred=[]
for element in yp:
  if element > 0.5:
    y_pred.append(1)
  else:
    y_pred.append(0)

from sklearn.metrics import classification_report, confusion_matrix
print(classification_report(y_test,y_pred))

#here, the diagonal values are the correctly predicted 
import seaborn as sn
cm=tf.math.confusion_matrix(labels=y_test, predictions=y_pred)

plt.figure(figsize=(10,7))#10,7 refers to height and width
sn.heatmap(cm, annot=True, fmt='d')
plt.xlabel("predicted")
plt.ylabel("truth")

